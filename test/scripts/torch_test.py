import torch
import os

print("=== PyTorch CUDA í™˜ê²½ í…ŒìŠ¤íŠ¸ ===")
print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'ì„¤ì •ë˜ì§€ ì•ŠìŒ')}")
print(f"PyTorch ë²„ì „: {torch.__version__}")
print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")

if torch.cuda.is_available():
    print("\n=== GPU ì •ë³´ ===")
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
        props = torch.cuda.get_device_properties(i)
        print(f"  ë©”ëª¨ë¦¬: {props.total_memory / 1024**3:.1f} GB")
    
    print("\n=== ê°„ë‹¨í•œ GPU í…ŒìŠ¤íŠ¸ ===")
    device = torch.device('cuda')
    x = torch.randn(1000, 1000, device=device)
    y = torch.randn(1000, 1000, device=device)
    z = torch.mm(x, y)
    print(f"GPU í–‰ë ¬ ê³±ì…ˆ ì„±ê³µ: {z.device}")
    print("ğŸ‰ PyTorch GPU í™˜ê²½ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
else:
    print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")